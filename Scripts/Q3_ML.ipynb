{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b38524",
   "metadata": {},
   "source": [
    "Can we predict the severity of an accident based on time, weather, and location data?\n",
    "    Using Random Forest, Logistic Regression, and SVM (multiclass classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b7e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f7931",
   "metadata": {},
   "source": [
    "###Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6aa201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample size for experiments: 90374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Severity', 'Start_Time', 'End_Time', 'Lat', 'Lng', 'Street',\n",
       "       'City', 'County', 'State', 'Wind_Chill(F)', 'Humidity(%)',\n",
       "       'Pressure(in)', 'Sunrise_Sunset', 'Severity_Label', 'Is_Day',\n",
       "       'Temperature(F)', 'Visibility(mi)', 'Wind_Speed(mph)',\n",
       "       'Precipitation(in)', 'Weather_Condition', 'Weather_Simple', 'Hour',\n",
       "       'Day_of_Week', 'Month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#dataset\n",
    "df = pd.read_csv('../Data/us_accidents_sample_500k_clean.csv')\n",
    "\n",
    "#target \n",
    "#df.Severity.value_counts() #already int\n",
    "\n",
    "# Extract time features from Start_Time\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "df['Hour'] = df['Start_Time'].dt.hour\n",
    "df['Day_of_Week'] = df['Start_Time'].dt.dayofweek\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "\n",
    "# Reduce high-cardinality by grouping rare categories for 'State' and 'Weather_Simple'\n",
    "state_counts = df['State'].value_counts()\n",
    "rare_states = state_counts[state_counts < 500].index  # threshold: group states with <500 occurrences\n",
    "df['State'] = df['State'].replace(rare_states, 'Other_State')\n",
    "\n",
    "weather_counts = df['Weather_Simple'].value_counts()\n",
    "rare_weather = weather_counts[weather_counts < 1000].index\n",
    "df['Weather_Simple'] = df['Weather_Simple'].replace(rare_weather, 'Other_Weather')\n",
    "\n",
    "# Small stratified subsample for fast experiments (optional)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.2, random_state=42)\n",
    "train_idx, _ = next(sss.split(df, df['Severity']))\n",
    "df_sample = df.iloc[train_idx].copy()\n",
    "print('Subsample size for experiments:', len(df_sample))\n",
    "\n",
    "# show columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c761229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified subsample created: df_sample with 90374 rows\n"
     ]
    }
   ],
   "source": [
    "# Stratified subsample for faster experiments (20% of data, preserves class balance)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.2, random_state=42)\n",
    "sample_idx, _ = next(sss.split(df, df['Severity']))\n",
    "df_sample = df.iloc[sample_idx].copy()\n",
    "print('Stratified subsample created: df_sample with', len(df_sample), 'rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e527b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and testing\n",
    "train, test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=df.Severity  #4 classes balanced\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328cf34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values per feature:\n",
      "Weather_Simple: 0\n",
      "Visibility(mi): 10185\n",
      "Sunrise_Sunset: 1166\n",
      "State: 0\n",
      "Hour: 0\n",
      "Day_of_Week: 0\n",
      "Month: 0\n",
      "Precipitation(in): 0\n",
      "Humidity(%): 10016\n",
      "Wind_Speed(mph): 0\n",
      "\n",
      "Training set size after dropping NAs: 350888\n",
      "Test set size after dropping NAs: 87662\n",
      "\n",
      "Training set size after dropping NAs: 350888\n",
      "Test set size after dropping NAs: 87662\n"
     ]
    }
   ],
   "source": [
    "#chose feature + target\n",
    "features = ['Weather_Simple', 'Visibility(mi)', 'Sunrise_Sunset', 'State', \n",
    "            'Hour', 'Day_of_Week', 'Month', 'Precipitation(in)', 'Humidity(%)', 'Wind_Speed(mph)']\n",
    "target = 'Severity'\n",
    "\n",
    "# check null values for new features\n",
    "print(\"Null values per feature:\")\n",
    "for col in features:\n",
    "    print(f\"{col}: {df[col].isnull().sum()}\")\n",
    "\n",
    "# create stratified train/test split\n",
    "train, test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=df.Severity  #4 classes balanced\n",
    ")\n",
    "\n",
    "# For ML: drop rows with missing values in features (after split to avoid leakage)\n",
    "train = train.dropna(subset=features + ['Severity'])\n",
    "test = test.dropna(subset=features + ['Severity'])\n",
    "print(f\"\\nTraining set size after dropping NAs: {len(train)}\")\n",
    "print(f\"Test set size after dropping NAs: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb54e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training and testing subsets\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8920248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing(OneHot and num combo)\n",
    "\n",
    "# numeric pipeline: impute then scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "num_features = ['Visibility(mi)', 'Precipitation(in)', 'Humidity(%)', 'Wind_Speed(mph)', 'Hour', 'Day_of_Week', 'Month']\n",
    "cat_features = ['Weather_Simple', 'Sunrise_Sunset', 'State']\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features),\n",
    "        ('num', numeric_transformer, num_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7c6e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "rand_forest = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', RandomForestClassifier(n_estimators=100, max_depth=12, max_features='sqrt', n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d75927",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#cross-validation only for Training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrand_forest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Cross-Validation Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Mean Cross-Validation accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cross-validation only for Training\n",
    "scores = cross_val_score(rand_forest, X_train, y_train, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Random Forest Cross-Validation Score:\", scores)\n",
    "print(\"Random Forest Mean Cross-Validation accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1978ad92",
   "metadata": {},
   "source": [
    "###logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "306a11d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 361499\n",
      "Test set size: 90375\n"
     ]
    }
   ],
   "source": [
    "#logistic regression multiclass \n",
    "#split data \n",
    "y = df[target] #target\n",
    "X = df[features] #Features\n",
    "#train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y           #stratify by the target == severity\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aed9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop rows with NAs\n",
    "train_data = pd.concat([X_train, y_train], axis=1).dropna(subset=features + [target])\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "\n",
    "test_data = pd.concat([X_test, y_test], axis=1).dropna(subset=features + [target])\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "830efe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "# reuse numeric_transformer defined earlier\n",
    "cat_cols = ['Weather_Simple', 'Sunrise_Sunset', 'State']\n",
    "num_cols = ['Visibility(mi)', 'Precipitation(in)', 'Humidity(%)', 'Wind_Speed(mph)', 'Hour', 'Day_of_Week', 'Month']\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features),\n",
    "        ('num', numeric_transformer, num_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a0a667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "log_model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32203ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression Cross-Validation scores: [0.77725213 0.77762262 0.77765112 0.77739463 0.77745162 0.77710964\n",
      " 0.77736613 0.77779361 0.77755928 0.77684679]\n",
      "logistic regression Mean Cross-Validation accuracy: 0.7774047547837349\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "scores = cross_val_score(\n",
    "    log_model, X_train, y_train, cv=10, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"logistic regression Cross-Validation scores:\", scores)\n",
    "print(\"logistic regression Mean Cross-Validation accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e866d3",
   "metadata": {},
   "source": [
    "###XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b8bc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#split training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "#EDA preprocessing reusing \n",
    "cat_cols = ['Weather_Simple', 'Sunrise_Sunset', 'State']\n",
    "num_cols = ['Visibility(mi)', 'Precipitation(in)', 'Humidity(%)', 'Wind_Speed(mph)', 'Hour', 'Day_of_Week', 'Month']\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features),\n",
    "        ('num', numeric_transformer, num_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26383470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder() #encode labels as ints\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf7fe99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob', #multi class classificaiton\n",
    "    eval_metric='mlogloss',    #evaluatoin metric\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', xgb_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b756a290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validation scores: [0.78143845 0.78251729 0.78141079 0.7819917  0.78204703 0.78121715\n",
      " 0.78052559 0.78143845 0.7806639  0.78198567]\n",
      "Mean Cross-Validation accuracy: 0.7815236016201118\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "scores_xgb = cross_val_score(\n",
    "    xgb_pipeline,\n",
    "    X_train,\n",
    "    y_train_encoded,\n",
    "    cv=10,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1    \n",
    ")\n",
    "print(\"XGBoost Cross-Validation scores:\", scores_xgb)\n",
    "print(\"Mean Cross-Validation accuracy:\", scores_xgb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf0a6cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validation scores: [0.78128981 0.78146935 0.78152733]\n",
      "Mean XGBoost Cross-Validation accuracy: 0.7814288322726949\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST model \n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder() #encode labels as ints\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', xgb.XGBClassifier(eval_metric='mlogloss', n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "scores_xgb = cross_val_score(xgb_pipeline, X_train, y_train_encoded, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "print(\"XGBoost Cross-Validation scores:\", scores_xgb)\n",
    "print(\"Mean XGBoost Cross-Validation accuracy:\", scores_xgb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f5914",
   "metadata": {},
   "source": [
    "###Best Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6277643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best hyperparameters: {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "Best CV accuracy: 0.7808759482466217\n",
      "Best hyperparameters: {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "Best CV accuracy: 0.7808759482466217\n",
      "Test set accuracy: 0.7816727886655563\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       857\n",
      "           2       0.79      0.99      0.88     68128\n",
      "           3       0.58      0.06      0.11     16413\n",
      "           4       0.62      0.01      0.01      2264\n",
      "\n",
      "    accuracy                           0.78     87662\n",
      "   macro avg       0.50      0.26      0.25     87662\n",
      "weighted avg       0.74      0.78      0.70     87662\n",
      "\n",
      "Test set accuracy: 0.7816727886655563\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       857\n",
      "           2       0.79      0.99      0.88     68128\n",
      "           3       0.58      0.06      0.11     16413\n",
      "           4       0.62      0.01      0.01      2264\n",
      "\n",
      "    accuracy                           0.78     87662\n",
      "   macro avg       0.50      0.26      0.25     87662\n",
      "weighted avg       0.74      0.78      0.70     87662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing the best ML model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#hyperparam tuning\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [3, 5],\n",
    "    'model__learning_rate': [0.1],\n",
    "    'model__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "#gridsearch\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_pipeline, \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_search.best_score_)\n",
    "#refit final model with best hyperparameter\n",
    "final_model = grid_search.best_estimator_\n",
    "final_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "#final Eval\n",
    "# Predict on test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Accuracy and classification report\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Test set accuracy:\", accuracy)\n",
    "print(\"Classification report:\\n\", classification_report(\n",
    "    y_test_encoded, \n",
    "    y_pred, \n",
    "    target_names=[str(c) for c in le.classes_],  # convert to strings\n",
    "    zero_division=0  \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dec955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
